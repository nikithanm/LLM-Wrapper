
1. Objective & Problem Statement
The objective of this project was to build an LLM-powered search application that integrates multiple AI models to provide accurate and consolidated responses. The project aimed to solve the problem of fragmented AI outputs by allowing inter-LLM conversations before generating a final response. Additionally, it provided user management and search history tracking to enhance user experience.

2. Methods, Approaches & Tools Used
To execute the project efficiently, the following technologies were used:

Backend: Flask (for handling API requests and user authentication)
Frontend: Streamlit (for an interactive and user-friendly UI)
Database: SQLite (to store user searches and history)
AI Model Integration: PyTorch (for any ML model-related tasks)
APIs: Gemini & Hugging Face (to generate responses from different LLMs)
Authentication: Admin and user authentication system for managing searches

3. Specific Tasks & Responsibilities
Backend Development: Built Flask-based APIs to handle user authentication, search history, and AI model interactions.
Database Management: Designed and implemented a relational database to store user data and search logs.
LLM Integration: Integrated Gemini and Hugging Face APIs to enable multi-model conversation.
Frontend Development: Created an interactive UI using Streamlit for users to input queries and view results.
User Management: Enabled login, registration, and anonymous search functionality.
Search Optimization: Ensured logged-in users could access their search history for a better user experience.

4. Independent or Team Project?
This was a team project, requiring collaboration to ensure seamless integration between backend, frontend, and AI models.

5. My Role & Contribution
Developed the backend using Flask, ensuring smooth API communication.
Handled database integration to store and retrieve user search history.
Worked on LLM API integration, ensuring responses from multiple models were consolidated properly.
Contributed to frontend integration with Streamlit for a user-friendly experience.
Helped in debugging and optimizing search processing for faster responses.

6. Outcomes & Impact
Successfully built a functional LLM-powered search engine with multi-model integration.  Enhanced user experience with search history tracking and anonymous search options.
Provided admin control for monitoring user searches.
Created a scalable system that can be expanded with more AI models in the future.
